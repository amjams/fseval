"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[238],{8215:function(e,t,n){var a=n(7294);t.Z=function(e){var t=e.children,n=e.hidden,r=e.className;return a.createElement("div",{role:"tabpanel",hidden:n,className:r},t)}},6396:function(e,t,n){n.d(t,{Z:function(){return c}});var a=n(7462),r=n(7294),i=n(2389),l=n(9443);var o=function(){var e=(0,r.useContext)(l.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},s=n(3810),d=n(6010),u="tabItem_vU9c";function p(e){var t,n,i,l=e.lazy,p=e.block,c=e.defaultValue,m=e.values,f=e.groupId,g=e.className,k=r.Children.map(e.children,(function(e){if((0,r.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),h=null!=m?m:k.map((function(e){var t=e.props;return{value:t.value,label:t.label,attributes:t.attributes}})),v=(0,s.lx)(h,(function(e,t){return e.value===t.value}));if(v.length>0)throw new Error('Docusaurus error: Duplicate values "'+v.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var b=null===c?c:null!=(t=null!=c?c:null==(n=k.find((function(e){return e.props.default})))?void 0:n.props.value)?t:null==(i=k[0])?void 0:i.props.value;if(null!==b&&!h.some((function(e){return e.value===b})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+b+'" but none of its children has the corresponding value. Available values are: '+h.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var N=o(),y=N.tabGroupChoices,C=N.setTabGroupChoices,_=(0,r.useState)(b),S=_[0],x=_[1],I=[],w=(0,s.o5)().blockElementScrollPositionUntilNextRender;if(null!=f){var T=y[f];null!=T&&T!==S&&h.some((function(e){return e.value===T}))&&x(T)}var E=function(e){var t=e.currentTarget,n=I.indexOf(t),a=h[n].value;a!==S&&(w(t),x(a),null!=f&&C(f,a))},P=function(e){var t,n=null;switch(e.key){case"ArrowRight":var a=I.indexOf(e.currentTarget)+1;n=I[a]||I[0];break;case"ArrowLeft":var r=I.indexOf(e.currentTarget)-1;n=I[r]||I[I.length-1]}null==(t=n)||t.focus()};return r.createElement("div",{className:"tabs-container"},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,d.Z)("tabs",{"tabs--block":p},g)},h.map((function(e){var t=e.value,n=e.label,i=e.attributes;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:S===t?0:-1,"aria-selected":S===t,key:t,ref:function(e){return I.push(e)},onKeyDown:P,onFocus:E,onClick:E},i,{className:(0,d.Z)("tabs__item",u,null==i?void 0:i.className,{"tabs__item--active":S===t})}),null!=n?n:t)}))),l?(0,r.cloneElement)(k.filter((function(e){return e.props.value===S}))[0],{className:"margin-vert--md"}):r.createElement("div",{className:"margin-vert--md"},k.map((function(e,t){return(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==S})}))))}function c(e){var t=(0,i.Z)();return r.createElement(p,(0,a.Z)({key:String(t)},e))}},2158:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return c},contentTitle:function(){return m},metadata:function(){return f},toc:function(){return g},default:function(){return h}});var a=n(7462),r=n(3366),i=(n(7294),n(3905)),l=n(6396),o=n(8215),s=n(9055),d=n(3221),u=n(6572),p=["components"],c={sidebar_position:0,title:"fseval.config.PipelineConfig"},m="PipelineConfig",f={unversionedId:"config/PipelineConfig",id:"config/PipelineConfig",title:"fseval.config.PipelineConfig",description:"The complete configuration needed to run the fseval pipeline.",source:"@site/docs/config/PipelineConfig.mdx",sourceDirName:"config",slug:"/config/PipelineConfig",permalink:"/fseval/docs/config/PipelineConfig",editUrl:"https://github.com/dunnkers/fseval/tree/website/docs/config/PipelineConfig.mdx",tags:[],version:"current",sidebarPosition:0,frontMatter:{sidebar_position:0,title:"fseval.config.PipelineConfig"},sidebar:"tutorialSidebar",previous:{title:"fseval.main",permalink:"/fseval/docs/main"},next:{title:"fseval.config.DatasetConfig",permalink:"/fseval/docs/config/DatasetConfig"}},g=[{value:"Examples",id:"examples",children:[],level:2}],k={toc:g};function h(e){var t=e.components,n=(0,r.Z)(e,p);return(0,i.kt)("wrapper",(0,a.Z)({},k,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"pipelineconfig"},"PipelineConfig"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'class fseval.config.PipelineConfig(\n    dataset: DatasetConfig=MISSING,   \n    cv: CrossValidatorConfig=MISSING,\n    resample: ResampleConfig=MISSING,\n    ranker: EstimatorConfig=MISSING,\n    validator: EstimatorConfig=MISSING,\n    storage: StorageConfig=MISSING,\n    callbacks: Dict[str, Any]=field(default_factory=lambda: {}),\n    metrics: Dict[str, Any]=field(default_factory=lambda: {}),\n    n_bootstraps: int=1,\n    n_jobs: Optional[int]=1,\n    all_features_to_select: str="range(1, min(50, p) + 1)",\n    defaults: List[Any] = field(\n        default_factory=lambda: [\n            "_self_",\n            {"dataset": MISSING},\n            {"cv": "kfold"},\n            {"resample": "shuffle"},\n            {"ranker": MISSING},\n            {"validator": MISSING},\n            {"storage": "local"},\n            {"callbacks": []},\n            {"metrics": ["feature_importances", "ranking_scores", "validation_scores"]},\n            {"override hydra/job_logging": "colorlog"},\n            {"override hydra/hydra_logging": "colorlog"},\n        ]\n    )\n)\n')),(0,i.kt)("p",null,"The complete configuration needed to run the fseval pipeline."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Attributes"),":"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null}),(0,i.kt)("th",{parentName:"tr",align:null}))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"dataset")," : ",(0,i.kt)("a",{parentName:"td",href:"../DatasetConfig"},"DatasetConfig")),(0,i.kt)("td",{parentName:"tr",align:null},"Determines the dataset to use for this experiment.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"cv")," : ",(0,i.kt)("a",{parentName:"td",href:"../CrossValidatorConfig"},"CrossValidatorConfig")),(0,i.kt)("td",{parentName:"tr",align:null},"The CV method and split to use in this experiment.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"resample")," : ",(0,i.kt)("a",{parentName:"td",href:"../ResampleConfig"},"ResampleConfig")),(0,i.kt)("td",{parentName:"tr",align:null},"Dataset resampling; e.g. with or without replacement.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"ranker")," : ",(0,i.kt)("a",{parentName:"td",href:"../EstimatorConfig"},"EstimatorConfig")),(0,i.kt)("td",{parentName:"tr",align:null},"A Feature Ranker or Feature Selector.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"validator")," : ",(0,i.kt)("a",{parentName:"td",href:"../EstimatorConfig"},"EstimatorConfig")),(0,i.kt)("td",{parentName:"tr",align:null},"Some estimator to validate the feature subsets.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"storage")," : ",(0,i.kt)("a",{parentName:"td",href:"../StorageConfig"},"StorageConfig")),(0,i.kt)("td",{parentName:"tr",align:null},"A storage method used to store the fit estimators.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"callbacks")," : Dict","[str, Any]"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("a",{parentName:"td",href:"../callbacks"},"Callbacks"),". Provide hooks for storing the config or results.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"metrics")," : Dict","[str, Any]"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("a",{parentName:"td",href:"../metrics"},"Metrics")," allow custom computation after any pipeline stage.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"n_bootstraps")," : int"),(0,i.kt)("td",{parentName:"tr",align:null},"Amount of 'bootstraps' to run. A bootstrap means running the pipeline again but with a resampled (see ",(0,i.kt)("inlineCode",{parentName:"td"},"resample"),") version of the dataset. This allows estimating stability, for example.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"n_jobs")," : Optional","[int]"),(0,i.kt)("td",{parentName:"tr",align:null},"Amount of CPU's to use for computing each bootstrap. This thus distributes the amount of bootstraps over CPU's.")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"all_features_to_select")," : str"),(0,i.kt)("td",{parentName:"tr",align:null},"Once the ranker has been fit, this determines the feature subsets to validate. By default, at most 50 subsets containing the highest ranked features are validated. The format of this parameter is a string that can contain an arbitrary Python expression. The condition is that the expression must evaluate to a ",(0,i.kt)("inlineCode",{parentName:"td"},"List[int]")," object. For example, the default is: ",(0,i.kt)("inlineCode",{parentName:"td"},"range(1, min(50, p) + 1)"),". Each number in the list is passed to the ",(0,i.kt)("inlineCode",{parentName:"td"},"sklearn.feature_selection.SelectFromModel")," as the ",(0,i.kt)("inlineCode",{parentName:"td"},"max_features")," parameter. To see how the expression is evaluated, check out the ",(0,i.kt)("a",{parentName:"td",href:"https://github.com/dunnkers/fseval/blob/e2ca739d341545f2c73c3d95277ec51db8a3fa87/fseval/pipelines/rank_and_validate/_dataset_validator.py#L23-L45"},"source code"),".")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("inlineCode",{parentName:"td"},"defaults")," : List","[Any]"),(0,i.kt)("td",{parentName:"tr",align:null},"Default values for the above. See Hydra docs on ",(0,i.kt)("a",{parentName:"td",href:"https://hydra.cc/docs/tutorials/structured_config/defaults/"},"Defaults List"),".")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null}),(0,i.kt)("td",{parentName:"tr",align:null})))),(0,i.kt)("p",null,"Experiments can be configured in two ways."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Using ",(0,i.kt)("strong",{parentName:"li"},"YAML")," files stored in a directory"),(0,i.kt)("li",{parentName:"ol"},"Using ",(0,i.kt)("strong",{parentName:"li"},"Python")," (",(0,i.kt)("a",{parentName:"li",href:"https://hydra.cc/docs/tutorials/structured_config/intro/"},"Structured Configs"),")")),(0,i.kt)("h2",{id:"examples"},"Examples"),(0,i.kt)(l.Z,{groupId:"config-representation",mdxType:"Tabs"},(0,i.kt)(o.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,i.kt)(s.Z,{className:"language-yaml",title:"conf/my_config.yaml",mdxType:"CodeBlock"},d.Z)),(0,i.kt)(o.Z,{value:"structured",label:"Structured Config",mdxType:"TabItem"},(0,i.kt)(s.Z,{className:"language-py",title:"conf/my_config.py",mdxType:"CodeBlock"},u.Z))),(0,i.kt)("p",null,"Using the ",(0,i.kt)("em",{parentName:"p"},"override")," keyword is required when overriding a config ",(0,i.kt)("strong",{parentName:"p"},"group"),". See more ",(0,i.kt)("a",{parentName:"p",href:"https://hydra.cc/docs/next/upgrades/1.0_to_1.1/defaults_list_override/#internaldocs-banner"},"here"),"."))}h.isMDXComponent=!0},6572:function(e,t){t.Z='from fseval.config import PipelineConfig\nfrom omegaconf import MISSING\n\n# To set PipelineConfig defaults in a Structured Config, we must redefine the entire\n# defaults list.\nmy_config = PipelineConfig(\n    n_bootstraps=1,\n    defaults=[\n        "_self_",\n        # highlight-next-line\n        {"dataset": "synthetic"},\n        {"cv": "kfold"},\n        {"resample": "shuffle"},\n        {"ranker": MISSING},\n        # highlight-next-line\n        {"validator": "knn"},\n        {"storage": "local"},\n        # highlight-next-line\n        {"callbacks": ["to_sql"]},\n        {"metrics": ["feature_importances", "ranking_scores", "validation_scores"]},\n        {"override hydra/job_logging": "colorlog"},\n        {"override hydra/hydra_logging": "colorlog"},\n    ],\n)\n'},3221:function(e,t){t.Z="defaults:\n  - _self_\n  - base_pipeline_config\n  - override dataset: synthetic\n  - override validator: knn\n  - override /callbacks:\n      - to_csv\n\nn_bootstraps: 1\n\ncallbacks:\n  to_csv:\n    dir: /Users/dunnkers/Downloads/results_dir\n"}}]);